# Parallel Computing for Machine Learning
### Machine learning, in general, is a statiscal approach to identify latent governing patterns in large datasets and make new discoveries with the uncovered patterns. However, the Internet today produces vast amount of data every second, and processing such enormous data with machine learning in real time is beyond the capibility of any single CPU human has created. One way to address this issue is to utilize high performance distributed computing technique. Based on devide & conquer algorithm, if we can break the standard machine learning problem into smaller and more manageable independent jobs, we will be able to complete the task quickly in a parallel fasion. This project explores a large family of machine learning algorithms, including supervised learning such as linear regression, logistic regression, random forrest, as well as unsupervised k-means clustering method. Our goal is to realize these algorithms using parallel computing framework, i.e. MapReduce and Apache Spark.

# Distributed algorithms for machine learning:

### Parallel computing techniques to be used:
### We will use Map-Reduce technique and possibly Apache Spark framework.

### Here, we hope to develop a general way of programming Machine Learning on multi-core, in order to take advantage of the massive computing power of modern computers and thus speed the learning process.

<img src="./pics/figure_1.png" />

### Example: how parallel linear regression works.

<img src="./pics/figure_2.png" />

### Expected result:
### we expect to parallelize a large class of machine learning algorithms on multicore processors, and find how much these learning algorithms can be improved in terms of running time.

# So what?

# What's next?

# References:
### 1.
### 2.
