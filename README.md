# Parallel Computing for Machine Learning
### Machine learning, in general, is a statiscal approach to identify latent governing patterns in large datasets and make new discoveries with the uncovered patterns. However, the Internet today produces vast amounts of data every second, and processing such enormous data with machine learning in real time is beyond the capibility of any single CPU human have created. One way to address this issue is to utilize high performance distributed computing technique. Based on devide & conquer algorithm, if we can break the standard machine learning problem into smaller and more manageable independent jobs, we will be able to complete the task quickly in a parallel fasion.

# How:
### Here, we hope to develop a general way of programming Machine Learning on multi-core, in order to take advantage of the massive computing power of modern computers and thus speed the learning process.

### Parallel computing techniques to be used:
### We will use Map-Reduce technique and possibly Apache Spark framework.

<img src="./pics/figure_1.png" />

### Expected result:
### we expect to parallelize a large class of machine learning algorithms on multicore processors, and find how much these learning algorithms can be improved in terms of running time.

### How it should work

<img src="./pics/figure_2.png" />

# So what?

# What's next?

# References:
### 1.
### 2.
